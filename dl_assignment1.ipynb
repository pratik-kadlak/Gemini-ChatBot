{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratik-kadlak/Gemini-ChatBot/blob/main/dl_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mAuPPqavEDm",
        "outputId": "5692a854-7d33-42e6-fec9-83ab5c831b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.42)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.42.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKB03cifU3KF"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import wandb\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTD0krw6GwIn",
        "outputId": "2527bd4b-d2ac-40ea-a13c-ebb55c4a1e11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow4bctElVK5B"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "k = len(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmodfLuwYKN_"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "vp-lMeA3VQ-_",
        "outputId": "8090d987-6113-4329-a9e7-0f07d66d6e93"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_sample_image_of_each_class():\n",
        "    \"\"\"\n",
        "    Plots one image of each class in the Fashion MNIST training data using Weights & Biases.\n",
        "    \"\"\"\n",
        "\n",
        "    (X_train, y_train), (_, _) = fashion_mnist.load_data()\n",
        "\n",
        "    class_names = [\n",
        "        \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "        \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "    ]\n",
        "\n",
        "    labels = []\n",
        "    images = []\n",
        "\n",
        "    for i in range(len(X_train)):\n",
        "        if class_names[y_train[i]] not in labels:\n",
        "            labels.append(class_names[y_train[i]])\n",
        "            images.append(np.array(X_train[i]))\n",
        "            if len(labels) == 10:  # Change 10 to the number of classes in your dataset\n",
        "                break\n",
        "\n",
        "    # for plotting the images in google colab\n",
        "    num_rows = 2\n",
        "    num_cols = 5\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5))\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        row_idx = i // num_cols\n",
        "        col_idx = i % num_cols\n",
        "\n",
        "        axes[row_idx, col_idx].axis(\"off\")\n",
        "        axes[row_idx, col_idx].imshow(images[i], cmap=\"gray\")\n",
        "        axes[row_idx, col_idx].set_title(labels[i])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # for plotting the images in wandb\n",
        "    # wandb.init(project=\"DL_Assignment_1\")\n",
        "    # for img, caption in zip(images, labels):\n",
        "    #     plot = wandb.Image(img, caption=caption)\n",
        "    #     wandb.log({\"Sample image for each class\": plot})\n",
        "\n",
        "    # wandb.finish()\n",
        "\n",
        "plot_sample_image_of_each_class()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMMAx9CEVoXB"
      },
      "source": [
        "##Question 2 & Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fY0Zd07z_3l"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "k = len(class_names)\n",
        "\n",
        "# loading the data\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#flattening the images, originally images is of size 28x28, converting it to 784x1\n",
        "X_train  = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
        "X_train = np.array(X_train)/255.0 # normalizing the input data\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
        "X_test = np.array(X_test)/255.0  # normalizing the input data\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0uHSicL1UN5"
      },
      "outputs": [],
      "source": [
        "def initialize_Wandb(neurons_per_layer, method):\n",
        "    \"\"\"\n",
        "        initializes weights and bias by the given method of initialization\n",
        "    \"\"\"\n",
        "\n",
        "    W = []\n",
        "    b = []\n",
        "    np.random.seed(42)\n",
        "\n",
        "    for l in range(len(neurons_per_layer)-1):\n",
        "        if method == \"random_uniform\":\n",
        "            W.append(np.random.uniform(-0.7, 0.7, (neurons_per_layer[l+1], neurons_per_layer[l])))\n",
        "            b.append(np.random.uniform(-0.7, 0.7, (neurons_per_layer[l+1],1)))\n",
        "        elif method == \"xavier\":\n",
        "            W.append(np.random.randn(neurons_per_layer[l+1],neurons_per_layer[l])*np.sqrt(6/(neurons_per_layer[l+1]+neurons_per_layer[l])))\n",
        "            b.append(np.zeros((neurons_per_layer[l+1], 1)))\n",
        "        else:\n",
        "            W.append(np.random.randn(neurons_per_layer[l+1], neurons_per_layer[l]) * 0.001)\n",
        "            b.append((np.random.randn(neurons_per_layer[l+1],1)) * 0.001)\n",
        "\n",
        "    return W, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYtjJqjzMGax"
      },
      "outputs": [],
      "source": [
        "# activation func and their derivatives\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0/(1.+np.exp(-x))\n",
        "\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x)*(1-sigmoid(x))\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return 1 - np.tanh(x)**2\n",
        "\n",
        "\n",
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "\n",
        "def identity_derivative(x):\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQrWnf9CMOgY"
      },
      "outputs": [],
      "source": [
        "# loss functions\n",
        "\n",
        "def cross_entropy(y, y_hat, W, weight_decay):\n",
        "    loss = 0\n",
        "    for i in range(len(y)):\n",
        "        for j in range(len(y[i])):\n",
        "            loss += -1.0 * y[i][j] * np.log(y_hat[i][j])\n",
        "\n",
        "    reg = 0\n",
        "    for i in range(len(W)):\n",
        "        reg += np.sum(np.square(W[i]))\n",
        "\n",
        "    regularized_loss = loss + weight_decay * reg\n",
        "    return regularized_loss\n",
        "\n",
        "\n",
        "def mean_square_error(y, y_hat, W, weight_decay):\n",
        "    loss = 0.5 * np.sum(np.square(y-y_hat))\n",
        "    reg = 0\n",
        "    for i in range(len(W)):\n",
        "        reg += np.sum(np.square(W[i]))\n",
        "\n",
        "    regularized_loss = loss + weight_decay * reg\n",
        "    return regularized_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86F1Id8eM8Y3"
      },
      "outputs": [],
      "source": [
        "# output functions\n",
        "\n",
        "def softmax(a):\n",
        "    return np.exp(a)/np.sum(np.exp(a), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQj2UPMPbsQ3"
      },
      "outputs": [],
      "source": [
        "# utility functions\n",
        "\n",
        "def evaluate_model(W, b, X, y, num_hidden_layers, activation_func, weight_decay, loss_func):\n",
        "    \"\"\"\n",
        "        calculates loss and accuracy of the model\n",
        "    \"\"\"\n",
        "    y_hat, activation, preactivation = forward_propogation(W, b, X, num_hidden_layers, activation_func)\n",
        "    y_pred = []\n",
        "    for i in range(len(y_hat[0])):\n",
        "        y_pred.append(np.argmax(y_hat[:,i]))\n",
        "\n",
        "    acc = 0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == y_pred[i]:\n",
        "            acc += 1\n",
        "\n",
        "    acc = (acc * 100) / len(y)\n",
        "\n",
        "    y_one_hot = generate_one_hot_matrix(len(y), y)\n",
        "\n",
        "    if loss_func == \"cross_entropy\":\n",
        "        loss = cross_entropy(y_one_hot, y_hat, W, weight_decay)\n",
        "    else:\n",
        "        loss = mean_square_error(y_one_hot, y_hat, W, weight_decay)\n",
        "\n",
        "    return acc, loss/len(y)\n",
        "\n",
        "\n",
        "def generate_one_hot_matrix(batch_size, y):\n",
        "    '''\n",
        "        generates one hot matrix, where the ith col gives the one hot vector for the ith image\n",
        "        and in that vector only the row number of true class will be 1 and rest will be zero\n",
        "    '''\n",
        "    y_one_hot = np.zeros((10,batch_size))\n",
        "    for i in range(batch_size):\n",
        "        y_one_hot[y[i]][i] = 1\n",
        "    return y_one_hot\n",
        "\n",
        "\n",
        "def split_train_val_data(X, y, validation_percent=0.1, random_seed=None):\n",
        "    \"\"\"\n",
        "    Split the data into training and validation sets.\n",
        "    \"\"\"\n",
        "    if random_seed is not None:\n",
        "        np.random.seed(random_seed)\n",
        "\n",
        "    num_samples = len(X)\n",
        "    num_val_samples = int(validation_percent * num_samples)\n",
        "\n",
        "    # Randomly shuffle indices\n",
        "    indices = np.arange(num_samples)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Split data based on shuffled indices\n",
        "    val_indices = indices[:num_val_samples]\n",
        "    train_indices = indices[num_val_samples:]\n",
        "\n",
        "    X_train, X_val = X[train_indices], X[val_indices]\n",
        "    y_train, y_val = y[train_indices], y[val_indices]\n",
        "\n",
        "    return X_train, X_val, y_train, y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M1SND281WuL"
      },
      "outputs": [],
      "source": [
        "def forward_propogation(W, b, X, num_hidden_layers, activation_func):\n",
        "    \"\"\"\n",
        "        does one forward pass of the data with the current weights and biases\n",
        "    \"\"\"\n",
        "\n",
        "    preactivation = []\n",
        "    activation = []\n",
        "\n",
        "    preactivation.append(X.T)\n",
        "    if activation_func == \"sigmoid\": activation.append(sigmoid(X.T))\n",
        "    elif activation_func == \"ReLU\": activation.append(relu(X.T))\n",
        "    else: activation.append(tanh(X.T))\n",
        "\n",
        "    for i in range(1, num_hidden_layers+1):\n",
        "        preactivation.append(np.matmul(W[i-1], activation[(i-1)]) + b[i-1])\n",
        "        if activation_func == \"sigmoid\":\n",
        "            activation.append(sigmoid(preactivation[i]))\n",
        "        elif activation_func == \"ReLU\":\n",
        "            activation.append(relu(preactivation[i]))\n",
        "        elif activation_func == \"tanh\":\n",
        "            activation.append(tanh(preactivation[i]))\n",
        "\n",
        "    preactivation.append(np.dot(W[-1], activation[-1]) + b[-1])\n",
        "    activation.append(softmax(preactivation[-1]))\n",
        "    y_hat = activation[-1]\n",
        "    return y_hat, activation, preactivation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PM_XFiuI5Op"
      },
      "outputs": [],
      "source": [
        "def backward_propogation(W, b, y_one_hot, activation, preactivation, L, activation_func, loss_func):\n",
        "    \"\"\"\n",
        "        back_propogation algorithm for updating the parameters\n",
        "    \"\"\"\n",
        "\n",
        "    grad_preactivation = []\n",
        "\n",
        "    # grad with respect to output units\n",
        "    if loss_func == \"cross_entropy\":\n",
        "        grad_preactivation.append(activation[L]-y_one_hot)\n",
        "    else:\n",
        "        grad_preactivation.append(np.multiply((activation[L]-y_one_hot) , -2*np.multiply(activation[L], 1-activation[L])))\n",
        "\n",
        "    grad_W = []\n",
        "    grad_b = []\n",
        "\n",
        "    for i in range(L, 0, -1):\n",
        "        # grad with respect to weights and biases\n",
        "        grad_W.append(np.matmul(grad_preactivation[-1], activation[i-1].T))\n",
        "        grad_b.append(np.sum(grad_preactivation[-1], axis=1, keepdims=True))\n",
        "\n",
        "        if i == 1:\n",
        "            break\n",
        "\n",
        "        # grad with respect to hidden units\n",
        "        grad_hi = np.matmul(W[i-1].T, grad_preactivation[-1])\n",
        "\n",
        "        if activation_func == \"sigmoid\":\n",
        "            grad_preactivation.append(np.multiply(grad_hi, sigmoid_derivative(preactivation[i-1])))\n",
        "        elif activation_func == \"ReLU\":\n",
        "            grad_preactivation.append(np.multiply(grad_hi, relu_derivative(preactivation[i-1])))\n",
        "        elif activation_func == \"tanh\":\n",
        "            grad_preactivation.append(np.multiply(grad_hi, tanh_derivative(preactivation[i-1])))\n",
        "\n",
        "    return grad_W[::-1], grad_b[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4n8rlFsWI2_"
      },
      "outputs": [],
      "source": [
        "# update rules for various types of gradient descent\n",
        "\n",
        "def update_parameters(W, grad_W, b, grad_b, eta):\n",
        "    \"\"\"\n",
        "    normal gradient descent\n",
        "    \"\"\"\n",
        "    for i in range(0, len(W)):\n",
        "        W[i] = W[i] - eta * grad_W[i]\n",
        "        b[i] = b[i] - eta * grad_b[i]\n",
        "\n",
        "    return W, b\n",
        "\n",
        "\n",
        "def update_parameters_mgd(W, grad_W, b, grad_b, eta, beta, W_history, b_history):\n",
        "    \"\"\"\n",
        "    momentum based gradient descent\n",
        "    \"\"\"\n",
        "    for t in range(len(W)):\n",
        "        W_history[t] = beta * W_history[t] + grad_W[t]\n",
        "        b_history[t] = beta * b_history[t] + grad_b[t]\n",
        "    for i in range(len(W)):\n",
        "        W[i] = W[i] - eta * W_history[i]\n",
        "        b[i] = b[i] - eta * b_history[i]\n",
        "\n",
        "    return W, b, W_history, b_history\n",
        "\n",
        "\n",
        "def update_parameters_nag(W, W_history, b, b_history, eta, beta):\n",
        "    \"\"\"\n",
        "        nesterov accelerated gradient descent\n",
        "    \"\"\"\n",
        "    for i in range(len(W)):\n",
        "        W_history[i] = beta * W_history[i]\n",
        "        b_history[i] = beta * b_history[i]\n",
        "\n",
        "    for i in range(len(W)):\n",
        "        W[i] = W[i] - eta * W_history[i]\n",
        "        b[i] = b[i] - eta * b_history[i]\n",
        "\n",
        "    return W, b, W_history, b_history\n",
        "\n",
        "\n",
        "def update_parameters_rmsprop(W, grad_W, b, grad_b, vt_W, vt_b, eta, beta, epsilon):\n",
        "    \"\"\"\n",
        "        rmsprop gradient descent\n",
        "    \"\"\"\n",
        "    for i in range(len(grad_W)):\n",
        "        vt_W[i] = beta * vt_W[i] + (1 - beta) * np.square(grad_W[i])\n",
        "        vt_b[i] = beta * vt_b[i] + (1 - beta) * np.square(grad_b[i])\n",
        "\n",
        "    for i in range(len(W)):\n",
        "        W[i] = W[i] - (eta/np.sqrt(vt_W[i]+epsilon)) * grad_W[i]\n",
        "        b[i] = b[i] - (eta/np.sqrt(vt_b[i]+epsilon)) * grad_b[i]\n",
        "\n",
        "    return W, b, vt_W, vt_b\n",
        "\n",
        "\n",
        "def update_parameters_adam(W, grad_W, vt_W, mt_W, b, grad_b, vt_b, mt_b, t, eta, beta1, beta2, epsilon):\n",
        "    for i in range(len(W)):\n",
        "        curr_mt_W = beta1 * mt_W[i] + (1 - beta1) * grad_W[i]\n",
        "        curr_mt_b = beta1 * mt_b[i] + (1 - beta1) * grad_b[i]\n",
        "\n",
        "        curr_vt_W = beta2 * vt_W[i] + (1 - beta2) * np.square(grad_W[i])\n",
        "        curr_vt_b = beta2 * vt_b[i] + (1 - beta2) * np.square(grad_b[i])\n",
        "\n",
        "        mt_W_hat = curr_mt_W / (1.0 - beta1**t)\n",
        "        mt_b_hat = curr_mt_b / (1.0 - beta1**t)\n",
        "\n",
        "        vt_W_hat = curr_vt_W / (1.0 - beta2**t)\n",
        "        vt_b_hat = curr_vt_b / (1.0 - beta2**t)\n",
        "\n",
        "        # saving for the next iteration\n",
        "        mt_W[i] = curr_mt_W\n",
        "        mt_b[i] = curr_mt_b\n",
        "        vt_W[i] = curr_vt_W\n",
        "        vt_b[i] = curr_vt_b\n",
        "\n",
        "        # updating the parameters\n",
        "        W[i] = W[i] - (eta/(np.sqrt(vt_W_hat) + epsilon)) * mt_W_hat\n",
        "        b[i] = b[i] - (eta/(np.sqrt(vt_b_hat) + epsilon)) * mt_b_hat\n",
        "\n",
        "    return W, b, vt_W, vt_b, mt_W, mt_b\n",
        "\n",
        "\n",
        "def update_parameters_nadam(W, grad_W, vt_W, mt_W, b, grad_b, vt_b, mt_b, t, eta, beta1, beta2, epsilon):\n",
        "    for i in range(len(W)):\n",
        "        curr_mt_W = beta1 * mt_W[i] + (1 - beta1) * grad_W[i]\n",
        "        curr_mt_b = beta1 * mt_b[i] + (1 - beta1) * grad_b[i]\n",
        "\n",
        "        curr_vt_W = beta2 * vt_W[i] + (1 - beta2) * np.square(grad_W[i])\n",
        "        curr_vt_b = beta2 * vt_b[i] + (1 - beta2) * np.square(grad_b[i])\n",
        "\n",
        "        mt_W_hat = curr_mt_W / (1.0 - beta1**t)\n",
        "        mt_b_hat = curr_mt_b / (1.0 - beta1**t)\n",
        "\n",
        "        vt_W_hat = curr_vt_W / (1.0 - beta2**t)\n",
        "        vt_b_hat = curr_vt_b / (1.0 - beta2**t)\n",
        "\n",
        "        # saving for the next iteration\n",
        "        mt_W[i] = curr_mt_W\n",
        "        mt_b[i] = curr_mt_b\n",
        "        vt_W[i] = curr_vt_W\n",
        "        vt_b[i] = curr_vt_b\n",
        "\n",
        "        # updating the parameters\n",
        "        W[i] = W[i] - (eta/(np.sqrt(vt_W_hat) + epsilon)) * ((1-beta1)*grad_W[i]/(1-beta1**t))\n",
        "        b[i] = b[i] - (eta/(np.sqrt(vt_b_hat) + epsilon)) * ((1-beta1)*grad_b[i]/(1-beta1**t))\n",
        "\n",
        "    return W, b, vt_W, vt_b, mt_W, mt_b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ce_loss = []\n",
        "ce_acc = []\n",
        "mse_loss = []\n",
        "mse_acc = []"
      ],
      "metadata": {
        "id": "VCk3J1qThSfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng__TfcbFmBq"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(X_train, X_val, y_train, y_val, config):\n",
        "    # # setting hyper parameters\n",
        "    num_hidden_layers = config.num_hidden_layers\n",
        "    size_of_hidden_layer = config.size_of_hidden_layer\n",
        "    activation_func = config.activation_func\n",
        "    loss_func = \"cross_entropy\"\n",
        "    method = config.method\n",
        "    num_images = len(X_train)\n",
        "    batch_size = config.batch_size\n",
        "    epoch = config.epochs\n",
        "    eta = config.eta\n",
        "    weight_decay = config.weight_decay\n",
        "    optimizer = config.optimizer\n",
        "\n",
        "    # setting batch_size = 1 for sgd\n",
        "    if optimizer == \"sgd\":\n",
        "        batch_size = 1\n",
        "\n",
        "    # used for momentum\n",
        "    beta = 0.5\n",
        "    W_history = [0] * (num_hidden_layers+1)\n",
        "    b_history = [0] * (num_hidden_layers+1)\n",
        "\n",
        "    # used for rmsprop\n",
        "    vt_W = [0] * (num_hidden_layers+1)\n",
        "    vt_b = [0] * (num_hidden_layers+1)\n",
        "    epsilon = 1e-8\n",
        "    beta = 0.5\n",
        "\n",
        "    # usef for adam and nadam\n",
        "    vt_W = [0] * (num_hidden_layers+1)\n",
        "    vt_b = [0] * (num_hidden_layers+1)\n",
        "    mt_W = [0] * (num_hidden_layers+1)\n",
        "    mt_b = [0] * (num_hidden_layers+1)\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    epsilon = 1e-8\n",
        "    t = 1\n",
        "\n",
        "    run_name = f\"opt_{optimizer}_act_{activation_func}_ep_{epoch}_eta_{eta}_L_{num_hidden_layers}_hs_{size_of_hidden_layer}_bs_{batch_size}_mthd_{method}_wd_{weight_decay}\"\n",
        "    y_pred = []\n",
        "\n",
        "    # making the list of structure of neural networks\n",
        "    neurons_per_layer = [X_train.shape[1]]\n",
        "    for i in range(num_hidden_layers):\n",
        "        neurons_per_layer.append(size_of_hidden_layer)\n",
        "    neurons_per_layer.append(k)\n",
        "\n",
        "\n",
        "    # Initialize W, b\n",
        "    W, b = initialize_Wandb(neurons_per_layer, method)\n",
        "\n",
        "    y_hat = []\n",
        "    for iteration in tqdm(range(epoch)):\n",
        "        for i in range(0, num_images, batch_size):\n",
        "            if i + batch_size > num_images:\n",
        "                X_batch = X_train[i:]\n",
        "                y_batch = y_train[i:]\n",
        "                batch_size = len(X_batch)\n",
        "            else:\n",
        "                X_batch = X_train[i:i+batch_size]\n",
        "                y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "            if optimizer == \"momentum\":\n",
        "                hL, activation, preactivation = forward_propogation(W, b, X_batch, num_hidden_layers, activation_func)\n",
        "                y_one_hot = generate_one_hot_matrix(batch_size, y_batch)\n",
        "                grad_W, grad_b = backward_propogation(W, b, y_one_hot, activation, preactivation, num_hidden_layers+1, activation_func, loss_func)\n",
        "                W, b, W_history, b_history = update_parameters_mgd(W, grad_W, b, grad_b, eta, beta, W_history, b_history)\n",
        "            elif optimizer == \"nag\":\n",
        "                W_look_ahead, b_look_ahead, W_history, b_history = update_parameters_nag(W, W_history, b, b_history, eta, beta) # updating by history\n",
        "                hL, activation, preactivation = forward_propogation(W_look_ahead, b_look_ahead, X_batch, num_hidden_layers, activation_func)\n",
        "                y_one_hot = generate_one_hot_matrix(batch_size, y_batch)\n",
        "                grad_W, grad_b = backward_propogation(W_look_ahead, b_look_ahead, y_one_hot, activation, preactivation, num_hidden_layers+1, activation_func, loss_func)\n",
        "                W, b = update_parameters(W, grad_W, b, grad_b, eta) # updating by the grad of lookahead point\n",
        "            elif optimizer == \"rmsprop\":\n",
        "                hL, activation, preactivation = forward_propogation(W, b, X_batch, num_hidden_layers, activation_func)\n",
        "                y_one_hot = generate_one_hot_matrix(batch_size, y_batch)\n",
        "                grad_W, grad_b = backward_propogation(W, b, y_one_hot, activation, preactivation, num_hidden_layers+1, activation_func, loss_func)\n",
        "                W, b, vt_W, vt_b = update_parameters_rmsprop(W, grad_W, b, grad_b, vt_W, vt_b, eta, beta, epsilon)\n",
        "            elif optimizer == \"adam\":\n",
        "                hL, activation, preactivation = forward_propogation(W, b, X_batch, num_hidden_layers, activation_func)\n",
        "                y_one_hot = generate_one_hot_matrix(batch_size, y_batch)\n",
        "                grad_W, grad_b = backward_propogation(W, b, y_one_hot, activation, preactivation, num_hidden_layers+1, activation_func, loss_func)\n",
        "                W, b, vt_W, vt_b, mt_W, mt_b = update_parameters_adam(W, grad_W, vt_W, mt_W, b, grad_b, vt_b, mt_b, t, eta, beta1, beta2, epsilon)\n",
        "                t += 1\n",
        "            elif optimizer == \"nadam\":\n",
        "                W_look_ahead, b_look_ahead, vt_W, vt_b = update_parameters_nag(W, W_history, b, b_history, eta, beta) # updating by history\n",
        "                hL, activation, preactivation = forward_propogation(W_look_ahead, b_look_ahead, X_batch, num_hidden_layers, activation_func)\n",
        "                y_one_hot = generate_one_hot_matrix(batch_size, y_batch)\n",
        "                grad_W, grad_b = backward_propogation(W, b, y_one_hot, activation, preactivation, num_hidden_layers+1, activation_func, loss_func)\n",
        "                W, b, vt_W, vt_b, mt_W, mt_b = update_parameters_nadam(W, grad_W, vt_W, mt_W, b, grad_b, vt_b, mt_b, t, eta, beta1, beta2, epsilon)\n",
        "                t += 1\n",
        "            else:\n",
        "                # this else block is for sgd\n",
        "                hL, activation, preactivation = forward_propogation(W, b, X_batch, num_hidden_layers, activation_func)\n",
        "                y_one_hot = generate_one_hot_matrix(batch_size, y_batch)\n",
        "                grad_W, grad_b = backward_propogation(W, b, y_one_hot, activation, preactivation, num_hidden_layers+1, activation_func, loss_func)\n",
        "                W, b = update_parameters(W, grad_W, b, grad_b, eta)\n",
        "\n",
        "\n",
        "        val_accuracy, val_loss = evaluate_model(W, b, X_val, y_val, num_hidden_layers, activation_func, weight_decay, loss_func)\n",
        "        train_accuracy, train_loss = evaluate_model(W, b, X_train, y_train, num_hidden_layers, activation_func, weight_decay, loss_func)\n",
        "        print(f\" val_accuracy:{val_accuracy}, val_loss:{val_loss}, train_accuracy:{train_accuracy}, train_loss:{train_loss}\")\n",
        "        wandb.log({\"val_accuracy\":val_accuracy, 'val_loss':val_loss, \"train_accuracy\":train_accuracy, \"train_loss\":train_loss, \"epoch\":iteration+1})\n",
        "\n",
        "        # saving val_accuracy and val_loss for comparing 2 loss func\n",
        "        if loss_func == \"cross_entropy\":\n",
        "            ce_acc.append(val_accuracy)\n",
        "            ce_loss.append(val_loss)\n",
        "        else :\n",
        "            mse_acc.append(val_accuracy)\n",
        "            mse_loss.append(val_loss)\n",
        "\n",
        "    wandb.run.name = run_name\n",
        "    wandb.run.save()\n",
        "    wandb.run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4 , Question 5 and Question 6"
      ],
      "metadata": {
        "id": "syp8LSSQYFeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = split_train_val_data(X_train, y_train)\n",
        "\n",
        "sweep_config = {\n",
        "\"name\": \"Cross Entropy Loss\",\n",
        "\"metric\": {\n",
        "    \"name\":\"val_accuracy\",\n",
        "    \"goal\": \"maximize\"\n",
        "},\n",
        "\"method\": \"bayes\",\n",
        "\"parameters\": {\n",
        "        \"eta\": {\n",
        "            \"values\": [1e-3, 1e-4]\n",
        "        },\n",
        "        \"activation_func\": {\n",
        "            \"values\": [\"sigmoid\", \"tanh\", \"ReLU\"]\n",
        "        },\n",
        "        \"method\": {\n",
        "            \"values\": [\"xavier\", \"random_uniform\", \"random_normal\"]\n",
        "        },\n",
        "        \"optimizer\": {\n",
        "            \"values\": [\"sgd\", \"momentum\", \"nag\", \"rmsprop\", \"adam\", \"nadam\"]\n",
        "        },\n",
        "        \"batch_size\": {\n",
        "            \"values\": [16,32]\n",
        "        },\n",
        "        \"epochs\": {\n",
        "            \"values\": [5, 10]\n",
        "        },\n",
        "        \"weight_decay\": {\n",
        "            \"values\": [0, 0.0005, 0.05]\n",
        "        },\n",
        "        \"size_of_hidden_layer\": {\n",
        "            \"values\": [32, 64, 128]\n",
        "        },\n",
        "        \"num_hidden_layers\": {\n",
        "            \"values\": [3, 4, 5]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "def train():\n",
        "    with wandb.init(project=\"DL_Assignment_1\") as run:\n",
        "        config = wandb.config\n",
        "        gradient_descent(X_train, X_val, y_train, y_val, config)\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project = \"DL_Assignment_1\")\n",
        "wandb.agent(sweep_id, train, count = 3)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "VeRB8ZjlYLIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJgyt1YHRBSz"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ESRLE4Kqz50"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_pred, y_test):\n",
        "    wandb.log({\"confusion_matrix\" : wandb.plot.confusion_matrix(y_true=y_test, preds=y_pred, class_names=None)})\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P440bBynrMhb"
      },
      "outputs": [],
      "source": [
        "def calc_test_accuracy(X_test, y_test, W, b, num_hidden_layers, activation_func):\n",
        "    hL, activation, preactivation = forward_propogation(W, b, X_test, num_hidden_layers, activation_func)\n",
        "    y_pred = []\n",
        "    for i in range(len(hL[0])):\n",
        "        y_pred.append(np.argmax(hL[:, i]))\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(y_test)):\n",
        "        if y_test[i] == y_pred[i]:\n",
        "            count += 1\n",
        "\n",
        "    return count * 100 / len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 8\n",
        "For plotting run the model once with loss func \"cross_entropy\" and once with \"mean_squared_error\""
      ],
      "metadata": {
        "id": "GrQ-vcw-txL6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h5UxpeJ59v-"
      },
      "outputs": [],
      "source": [
        "# plotting loss\n",
        "\n",
        "x = [1,2,3,4,5,6,7,8,9,10]\n",
        "plt.plot(x, ce_loss, label=\"cross_entropy_loss\")\n",
        "plt.plot(x, mse_loss, label=\"mean_square_loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.savefig(\"loss.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting accuracy\n",
        "\n",
        "x = [1,2,3,4,5,6,7,8,9,10]\n",
        "plt.plot(x, ce_acc, label=\"cross_entropy\")\n",
        "plt.plot(x, mse_acc, label=\"mean_square_error\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig(\"acc.jpg\")"
      ],
      "metadata": {
        "id": "RDK7RrDxdWl2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdQKExbVmVuQ6JWnH0ngqZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}